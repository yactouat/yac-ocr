{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits classifier\n",
    "\n",
    "Let's build a model that is able to recognize a single digit from 0 to 9 from an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# setting up dependencies and data\n",
    "\n",
    "# loading and setting up dependencies\n",
    "import fastbook\n",
    "\n",
    "fastbook.setup_book()\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.nn import functional as F, CrossEntropyLoss\n",
    "\n",
    "# checking that we're using GPU for this one\n",
    "print(torch.cuda.get_device_name())\n",
    "\n",
    "# import MNIST dataset\n",
    "path_to_mnist = untar_data(URLs.MNIST)\n",
    "Path.BASE_PATH = path_to_mnist\n",
    "\n",
    "# sorting files\n",
    "mnist_training_files_0s = (path_to_mnist / 'training' / '0').ls().sorted()\n",
    "mnist_training_files_1s = (path_to_mnist / 'training' / '1').ls().sorted()\n",
    "mnist_training_files_2s = (path_to_mnist / 'training' / '2').ls().sorted()\n",
    "mnist_training_files_3s = (path_to_mnist / 'training' / '3').ls().sorted()\n",
    "mnist_training_files_4s = (path_to_mnist / 'training' / '4').ls().sorted()\n",
    "mnist_training_files_5s = (path_to_mnist / 'training' / '5').ls().sorted()\n",
    "mnist_training_files_6s = (path_to_mnist / 'training' / '6').ls().sorted()\n",
    "mnist_training_files_7s = (path_to_mnist / 'training' / '7').ls().sorted()\n",
    "mnist_training_files_8s = (path_to_mnist / 'training' / '8').ls().sorted()\n",
    "mnist_training_files_9s = (path_to_mnist / 'training' / '9').ls().sorted()\n",
    "\n",
    "# loading images\n",
    "list_0s = [tensor(Image.open(digit)) for digit in mnist_training_files_0s]\n",
    "list_1s = [tensor(Image.open(digit)) for digit in mnist_training_files_1s]\n",
    "list_2s = [tensor(Image.open(digit)) for digit in mnist_training_files_2s]\n",
    "list_3s = [tensor(Image.open(digit)) for digit in mnist_training_files_3s]\n",
    "list_4s = [tensor(Image.open(digit)) for digit in mnist_training_files_4s]\n",
    "list_5s = [tensor(Image.open(digit)) for digit in mnist_training_files_5s]\n",
    "list_6s = [tensor(Image.open(digit)) for digit in mnist_training_files_6s]\n",
    "list_7s = [tensor(Image.open(digit)) for digit in mnist_training_files_7s]\n",
    "list_8s = [tensor(Image.open(digit)) for digit in mnist_training_files_8s]\n",
    "list_9s = [tensor(Image.open(digit)) for digit in mnist_training_files_9s]\n",
    "\n",
    "# stacking images into rank-3 tensors and normalizing them\n",
    "stacked_0s = torch.stack(list_0s).float()/255\n",
    "stacked_1s = torch.stack(list_1s).float()/255\n",
    "stacked_2s = torch.stack(list_2s).float()/255\n",
    "stacked_3s = torch.stack(list_3s).float()/255\n",
    "stacked_4s = torch.stack(list_4s).float()/255\n",
    "stacked_5s = torch.stack(list_5s).float()/255\n",
    "stacked_6s = torch.stack(list_6s).float()/255\n",
    "stacked_7s = torch.stack(list_7s).float()/255\n",
    "stacked_8s = torch.stack(list_8s).float()/255\n",
    "stacked_9s = torch.stack(list_9s).float()/255\n",
    "\n",
    "# `torch.cat` concatenates tensors along the first dimension;\n",
    "# then `view` reshapes the concatenated tensor into a rank-2 tensor,\n",
    "# this new tensor has 28*28 columns and a number of rows equal to the number of images in the concatenated tensors;\n",
    "# a 28*28 image is flattened into a 784 pixels vector\n",
    "train_x = torch.cat([stacked_0s, stacked_1s, stacked_2s, stacked_3s, \n",
    "    stacked_4s, stacked_5s, stacked_6s, stacked_7s, \n",
    "    stacked_8s, stacked_9s]).view(-1, 28*28)\n",
    "# let's label each image\n",
    "train_y = tensor([0]*len(list_0s) + [1]*len(list_1s) + [2]*len(list_2s) + [3]*len(list_3s) + [4]*len(list_4s) + [5]*len(list_5s) + [6]*len(list_6s) + [7]*len(list_7s) + [8]*len(list_8s)+ [9]*len(list_9s)).unsqueeze(1)\n",
    "# When indexed, a `Dataset` is required to return a tuple of `(x,y)`, where `x` is the input data and `y` is the label.\n",
    "train_set = list(zip(train_x,train_y))\n",
    "\n",
    "# let's prepare our valid set by using the MNIST testing set\n",
    "mnist_valid_files_0s = (path_to_mnist / 'testing' / '0').ls().sorted()\n",
    "mnist_valid_files_1s = (path_to_mnist / 'testing' / '1').ls().sorted()\n",
    "mnist_valid_files_2s = (path_to_mnist / 'testing' / '2').ls().sorted()\n",
    "mnist_valid_files_3s = (path_to_mnist / 'testing' / '3').ls().sorted()\n",
    "mnist_valid_files_4s = (path_to_mnist / 'testing' / '4').ls().sorted()\n",
    "mnist_valid_files_5s = (path_to_mnist / 'testing' / '5').ls().sorted()\n",
    "mnist_valid_files_6s = (path_to_mnist / 'testing' / '6').ls().sorted()\n",
    "mnist_valid_files_7s = (path_to_mnist / 'testing' / '7').ls().sorted()\n",
    "mnist_valid_files_8s = (path_to_mnist / 'testing' / '8').ls().sorted()\n",
    "mnist_valid_files_9s = (path_to_mnist / 'testing' / '9').ls().sorted()\n",
    "\n",
    "list_0s_valid = [tensor(Image.open(digit)) for digit in mnist_valid_files_0s]\n",
    "list_1s_valid = [tensor(Image.open(digit)) for digit in mnist_valid_files_1s]\n",
    "list_2s_valid = [tensor(Image.open(digit)) for digit in mnist_valid_files_2s]\n",
    "list_3s_valid = [tensor(Image.open(digit)) for digit in mnist_valid_files_3s]\n",
    "list_4s_valid = [tensor(Image.open(digit)) for digit in mnist_valid_files_4s]\n",
    "list_5s_valid = [tensor(Image.open(digit)) for digit in mnist_valid_files_5s]\n",
    "list_6s_valid = [tensor(Image.open(digit)) for digit in mnist_valid_files_6s]\n",
    "list_7s_valid = [tensor(Image.open(digit)) for digit in mnist_valid_files_7s]\n",
    "list_8s_valid = [tensor(Image.open(digit)) for digit in mnist_valid_files_8s]\n",
    "list_9s_valid = [tensor(Image.open(digit)) for digit in mnist_valid_files_9s]\n",
    "\n",
    "stacked_0s_valid = torch.stack(list_0s_valid).float()/255\n",
    "stacked_1s_valid = torch.stack(list_1s_valid).float()/255\n",
    "stacked_2s_valid = torch.stack(list_2s_valid).float()/255\n",
    "stacked_3s_valid = torch.stack(list_3s_valid).float()/255\n",
    "stacked_4s_valid = torch.stack(list_4s_valid).float()/255\n",
    "stacked_5s_valid = torch.stack(list_5s_valid).float()/255\n",
    "stacked_6s_valid = torch.stack(list_6s_valid).float()/255\n",
    "stacked_7s_valid = torch.stack(list_7s_valid).float()/255\n",
    "stacked_8s_valid = torch.stack(list_8s_valid).float()/255\n",
    "stacked_9s_valid = torch.stack(list_9s_valid).float()/255\n",
    "\n",
    "# now, let's put together our validation set\n",
    "valid_x = torch.cat([stacked_0s_valid, stacked_1s_valid, stacked_2s_valid, stacked_3s_valid, \n",
    "    stacked_4s_valid, stacked_5s_valid, stacked_6s_valid, stacked_7s_valid, \n",
    "    stacked_8s_valid, stacked_9s_valid]).view(-1, 28*28)\n",
    "valid_y = tensor([0]*len(list_0s_valid) + [1]*len(list_1s_valid) + [2]*len(list_2s_valid) + [3]*len(list_3s_valid) + [4]*len(list_4s_valid) + [5]*len(list_5s_valid) + [6]*len(list_6s_valid) + [7]*len(list_7s_valid) + [8]*len(list_8s_valid)+ [9]*len(list_9s_valid)).unsqueeze(1)\n",
    "valid_set = list(zip(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8538 "
     ]
    }
   ],
   "source": [
    "# let's define our linear model\n",
    "# The equation `batch @ weights + bias` is a fundamental equation of any neural network.\n",
    "def linear_sgd_model(independent_variables): return (independent_variables@weights + bias)\n",
    "\n",
    "# let's define a metric to measure the accuracy of our model\n",
    "def batch_accuracy(preds, targets):\n",
    "    probs = torch.softmax(preds, dim=1)\n",
    "    preds_labels = torch.argmax(probs, dim=1)\n",
    "    true_labels = targets.view(preds_labels.shape)\n",
    "    correct_count = (preds_labels == true_labels).sum().item()\n",
    "    return tensor([correct_count / len(true_labels)])\n",
    "\n",
    "# let's define our loss function\n",
    "def mnist_loss(preds, targets):\n",
    "    # flatten the targets tensor to make it one-dimensional\n",
    "    targets = targets.flatten()\n",
    "    # measures the dissimilarity between the predicted probability distribution and the true distribution, aiming to minimize this difference\n",
    "    loss_function = CrossEntropyLoss()\n",
    "    return loss_function(preds, targets.long())\n",
    "\n",
    "#  function to calculate the gradient of the loss\n",
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()\n",
    "\n",
    "# defining training and validation functions\n",
    "def train_epoch(model, lr, params):\n",
    "    for xb,yb in training_data_loader:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()\n",
    "\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in validation_data_loader]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "# let's initialize our parameters (weights) for every pixel with random values\n",
    "# this function returns a tensor of size `size` filled with random values from a normal distribution with a standard deviation of `std`\n",
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()\n",
    "# let's initialize our weights with 10 output nodes, one for each digit\n",
    "weights = init_params((28*28,10))\n",
    "# the bias as well will be subject to gradient descent\n",
    "bias = init_params(1)\n",
    "\n",
    "# let's create datas loaders for training and validation sets\n",
    "training_data_loader = DataLoader(train_set, batch_size=64)\n",
    "validation_data_loader = DataLoader(valid_set, batch_size=64)\n",
    "\n",
    "for i in range(299):\n",
    "    params = weights,bias\n",
    "    train_epoch(linear_sgd_model, 0.001, params)\n",
    "    # validate_epoch(linear_model)\n",
    "    # print(validate_epoch(linear_sgd_model), end='\\n')\n",
    "\n",
    "# printing the last accuracy achieved\n",
    "print(validate_epoch(linear_sgd_model), end=' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reaching almost 86% accuracy with a simple linear SGD classifier for all digits is not bad at all!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
